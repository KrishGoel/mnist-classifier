{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/mnist_train.csv\")\n",
    "data = np.array(data)\n",
    "\n",
    "labels_raw = data[:, 0]\n",
    "labels = np.eye(10)[labels_raw]\n",
    "images = data[:, 1:]\n",
    "images = images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e0cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size_1 = 128\n",
    "hidden_size_2 = 128\n",
    "output_size = 10\n",
    "try:\n",
    "    weights_and_biases = np.load(\"./model/weights.npz\")\n",
    "    \n",
    "    b1 = weights_and_biases['b1']\n",
    "    w1 = weights_and_biases['w1']\n",
    "    b2 = weights_and_biases['b2']\n",
    "    w2 = weights_and_biases['w2']\n",
    "    b3 = weights_and_biases['b3']\n",
    "    w3 = weights_and_biases['w3']\n",
    "\n",
    "except FileNotFoundError:\n",
    "    b1 = np.zeros(hidden_size_1)\n",
    "    w1 = np.random.randn(input_size, hidden_size_1) * 0.01\n",
    "    b2 = np.zeros(hidden_size_2)\n",
    "    w2 = np.random.randn(hidden_size_1, hidden_size_2) * 0.01\n",
    "    b3 = np.zeros(output_size)\n",
    "    w3 = np.random.randn(hidden_size_2, output_size) * 0.01\n",
    "    b1 = np.zeros(hidden_size_1)\n",
    "    w1 = np.random.randn(input_size, hidden_size_1) * 0.01\n",
    "    b2 = np.zeros(hidden_size_2)\n",
    "    w2 = np.random.randn(hidden_size_1, hidden_size_2) * 0.01\n",
    "    b3 = np.zeros(output_size)\n",
    "    w3 = np.random.randn(hidden_size_2, output_size) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142ac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def d_relu(x):\n",
    "    return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d437c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(image_batch, w1, b1, w2, b2, w3, b3):\n",
    "    z1 = np.dot(image_batch, w1) + b1\n",
    "    a1 = relu(z1)\n",
    "    \n",
    "    z2 = np.dot(a1, w2) + b2\n",
    "    a2 = relu(z2)\n",
    "    \n",
    "    z3 = np.dot(a2, w3) + b3\n",
    "    y_pred = softmax(z3)\n",
    "    \n",
    "    return z1, a1, z2, a2, z3, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calculation(y_true, y_pred, batch_size, epsilon=1e-10):\n",
    "    return (-1 / batch_size) * np.sum(y_true * np.log(y_pred + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da1c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(y_true, y_pred, image_batch, z1, a1, z2, a2, z3, w1, w2, w3, b1, b2, b3):\n",
    "    e3 = y_pred - y_true\n",
    "    dw3 = np.dot(a2.T, e3)\n",
    "    db3 = np.sum(e3, axis = 0)\n",
    "    \n",
    "    e2 = np.dot(e3, w3.T) * d_relu(z2)\n",
    "    dw2 = np.dot(a1.T, e2)\n",
    "    db2 = np.sum(e2, axis = 0)\n",
    "    \n",
    "    e1 = np.dot(e2, w2.T) * d_relu(z1)\n",
    "    dw1 = np.dot(image_batch.T, e1)\n",
    "    db1 = np.sum(e1, axis = 0)\n",
    "    \n",
    "    return dw3, db3, dw2, db2, dw1, db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f049fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(learning_rate, w1, w2, w3, b1, b2, b3, dw1, dw2, dw3, db1, db2, db3):\n",
    "    w1 -= dw1 * learning_rate\n",
    "    b1 -= db1 * learning_rate\n",
    "    w2 -= dw2 * learning_rate\n",
    "    b2 -= db2 * learning_rate\n",
    "    w3 -= dw3 * learning_rate\n",
    "    b3 -= db3 * learning_rate\n",
    "    \n",
    "    return w1, w2, w3, b1, b2, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d2e4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.002252530529977633\n",
      "Epoch: 1, Loss: 0.0031937600052444138\n",
      "Epoch: 2, Loss: 0.0026350256948323453\n",
      "Epoch: 3, Loss: 0.002311421156375993\n",
      "Epoch: 4, Loss: 0.002275652934013489\n",
      "Epoch: 5, Loss: 0.0019711665530403725\n",
      "Epoch: 6, Loss: 0.0017708402127275323\n",
      "Epoch: 7, Loss: 0.0016830557597379448\n",
      "Epoch: 8, Loss: 0.0015650214798410976\n",
      "Epoch: 9, Loss: 0.0014392666133716421\n",
      "Epoch: 10, Loss: 0.0013592623020034864\n",
      "Epoch: 11, Loss: 0.0012861785663351249\n",
      "Epoch: 12, Loss: 0.001207923540777294\n",
      "Epoch: 13, Loss: 0.0011109420092897235\n",
      "Epoch: 14, Loss: 0.0010695278162349048\n",
      "Epoch: 15, Loss: 0.0010164678600786865\n",
      "Epoch: 16, Loss: 0.0009612516830931794\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m batch_images \u001b[38;5;241m=\u001b[39m images[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m      8\u001b[0m batch_labels \u001b[38;5;241m=\u001b[39m labels[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m---> 10\u001b[0m z1, a1, z2, a2, z3, y_pred \u001b[38;5;241m=\u001b[39m forward_propagation(batch_images, w1, b1, w2, b2, w3, b3)\n\u001b[0;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_calculation(batch_labels, y_pred, batch_size)\n\u001b[0;32m     14\u001b[0m dw3, db3, dw2, db2, dw1, db1 \u001b[38;5;241m=\u001b[39m backward_propagation(batch_labels, y_pred, batch_images, z1, a1, z2, a2, z3, w1, w2, w3, b1, b2, b3)\n",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m, in \u001b[0;36mforward_propagation\u001b[1;34m(image_batch, w1, b1, w2, b2, w3, b3)\u001b[0m\n\u001b[0;32m      5\u001b[0m z2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a1, w2) \u001b[38;5;241m+\u001b[39m b2\n\u001b[0;32m      6\u001b[0m a2 \u001b[38;5;241m=\u001b[39m relu(z2)\n\u001b[1;32m----> 8\u001b[0m z3 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a2, w3) \u001b[38;5;241m+\u001b[39m b3\n\u001b[0;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m softmax(z3)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z1, a1, z2, a2, z3, y_pred\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 200\n",
    "batch_size = 60\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch_images = images[i:i+batch_size]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "\n",
    "        z1, a1, z2, a2, z3, y_pred = forward_propagation(batch_images, w1, b1, w2, b2, w3, b3)\n",
    "\n",
    "        loss = loss_calculation(batch_labels, y_pred, batch_size)\n",
    "\n",
    "        dw3, db3, dw2, db2, dw1, db1 = backward_propagation(batch_labels, y_pred, batch_images, z1, a1, z2, a2, z3, w1, w2, w3, b1, b2, b3)\n",
    "\n",
    "        w1, w2, w3, b1, b2, b3 = update_parameters(learning_rate, w1, w2, w3, b1, b2, b3, dw1, dw2, dw3, db1, db2, db3)\n",
    "\n",
    "    weights_and_biases = {\n",
    "        \"b1\": b1,\n",
    "        \"w1\": w1,\n",
    "        \"b2\": b2,\n",
    "        \"w2\": w2,\n",
    "        \"b3\": b3,\n",
    "        \"w3\": w3\n",
    "    }\n",
    "    np.savez(\"./model/weights.npz\", **weights_and_biases)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, Loss: {loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
